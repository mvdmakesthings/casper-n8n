name: n8n-gpu

networks:
  frontend:
    name: frontend
    driver: bridge
  ollama-net:
    external: true

volumes:
  n8n_data:
    name: n8n-data
  n8n_patched_data:
    name: n8n-patched-data
  tailscale_state:
    name: tailscale-state

services:
  tailscale:
    container_name: tailscale
    image: tailscale/tailscale:latest
    hostname: ${TS_HOSTNAME:-n8n-gpu}
    environment:
      - TS_AUTHKEY=${TS_AUTHKEY}
      - TS_HOSTNAME=${TS_HOSTNAME:-n8n-gpu}
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_SERVE_CONFIG=/config/serve-config.json
      - TS_USERSPACE=false
    volumes:
      - tailscale_state:/var/lib/tailscale
      - ./tailscale/serve-config.json:/config/serve-config.json:ro
    cap_add:
      - NET_ADMIN
      - SYS_MODULE
    devices:
      - /dev/net/tun:/dev/net/tun
    networks:
      - frontend
    restart: unless-stopped

  n8n-patched:
    container_name: n8n-patched
    build:
      context: ./n8n
      dockerfile: Dockerfile
      args:
        N8N_VERSION: ${N8N_VERSION:-2.8.3}
        NODE_VERSION: ${NODE_VERSION:-22}
    image: jlyve-n8n:${N8N_VERSION:-2.8.3}
    environment:
      - N8N_ENCRYPTION_KEY=${N8N_PATCHED_ENCRYPTION_KEY}
      - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_PATCHED_JWT_SECRET}
      - WEBHOOK_URL=${WEBHOOK_URL_PATCHED:-http://localhost:5679}
      - N8N_AI_ENABLED=true
      - N8N_DEV_LICENSE_BYPASS=true
    ports:
      - "5679:5678"
    volumes:
      - n8n_patched_data:/home/node/.n8n
    tmpfs:
      - /tmp
      - /home/node/.cache
    read_only: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"
    networks:
      - frontend
      - ollama-net
    profiles:
      - patched
    restart: unless-stopped

  n8n:
    container_name: n8n
    image: n8nio/n8n:latest
    environment:
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - N8N_USER_MANAGEMENT_JWT_SECRET=${N8N_USER_MANAGEMENT_JWT_SECRET}
      - WEBHOOK_URL=${WEBHOOK_URL}
      - N8N_AI_ENABLED=true
    volumes:
      - n8n_data:/home/node/.n8n
    tmpfs:
      - /tmp
      - /home/node/.cache
    read_only: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"
    networks:
      - frontend
      - ollama-net
    depends_on:
      tailscale:
        condition: service_started
    restart: unless-stopped
